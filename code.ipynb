{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Import necessary libraries\n",
    "import itertools\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate Synthetic Transaction Data\n",
    "transactions = [\n",
    "    {'Milk', 'Bread', 'Shoes'},\n",
    "    {'Milk', 'Bread', 'Clothes'},\n",
    "    {'Milk', 'Shoes'},\n",
    "    {'Clothes', 'Bread'},\n",
    "    {'Milk', 'Clothes', 'Shoes', 'Bread'},\n",
    "    {'Bread', 'Shoes'},\n",
    "    {'Clothes', 'Milk'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define Minimum Item Support (MIS)\n",
    "MIS = {\n",
    "    'Milk': 0.3,    # 30%\n",
    "    'Bread': 0.2,   # 20%\n",
    "    'Shoes': 0.1,   # 10%\n",
    "    'Clothes': 0.15 # 15%\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Calculate Support of Each Item\n",
    "def calculate_support(transactions):\n",
    "    item_counts = {}\n",
    "    total_transactions = len(transactions)\n",
    "\n",
    "    for txn in transactions:\n",
    "        for item in txn:\n",
    "            item_counts[item] = item_counts.get(item, 0) + 1\n",
    "\n",
    "    support = {item: count / total_transactions for item, count in item_counts.items()}\n",
    "    return support\n",
    "\n",
    "support = calculate_support(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Generate Frequent Itemsets Based on MIS\n",
    "def generate_frequent_itemsets(transactions, MIS, support):\n",
    "    L = [item for item in support if support[item] >= MIS[item]]\n",
    "    L.sort(key=lambda item: MIS[item])  # Sort by MIS values\n",
    "\n",
    "    frequent_itemsets = []\n",
    "    for k in range(1, len(L) + 1):  # Iterate through different sizes of itemsets\n",
    "        candidates = list(itertools.combinations(L, k))\n",
    "        valid_itemsets = []\n",
    "\n",
    "        for itemset in candidates:\n",
    "            min_mis = min(MIS[item] for item in itemset)\n",
    "            itemset_support = sum(1 for txn in transactions if set(itemset).issubset(txn)) / len(transactions)\n",
    "\n",
    "            if itemset_support >= min_mis:\n",
    "                valid_itemsets.append(itemset)\n",
    "\n",
    "        if valid_itemsets:\n",
    "            frequent_itemsets.extend(valid_itemsets)\n",
    "\n",
    "    return frequent_itemsets\n",
    "\n",
    "frequent_itemsets = generate_frequent_itemsets(transactions, MIS, support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Generate Association Rules\n",
    "def generate_rules(frequent_itemsets, transactions, min_conf=0.6):\n",
    "    rules = []\n",
    "\n",
    "    for itemset in frequent_itemsets:\n",
    "        if len(itemset) > 1:\n",
    "            for i in range(1, len(itemset)):\n",
    "                for antecedent in itertools.combinations(itemset, i):\n",
    "                    consequent = tuple(set(itemset) - set(antecedent))\n",
    "\n",
    "                    support_antecedent = sum(1 for txn in transactions if set(antecedent).issubset(txn)) / len(transactions)\n",
    "                    support_itemset = sum(1 for txn in transactions if set(itemset).issubset(txn)) / len(transactions)\n",
    "\n",
    "                    confidence = support_itemset / support_antecedent if support_antecedent > 0 else 0\n",
    "\n",
    "                    if confidence >= min_conf:\n",
    "                        rules.append((antecedent, consequent, confidence))\n",
    "\n",
    "    return rules\n",
    "\n",
    "rules = generate_rules(frequent_itemsets, transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Frequent Itemsets:\n",
      "('Shoes',)\n",
      "('Clothes',)\n",
      "('Bread',)\n",
      "('Milk',)\n",
      "('Shoes', 'Clothes')\n",
      "('Shoes', 'Bread')\n",
      "('Shoes', 'Milk')\n",
      "('Clothes', 'Bread')\n",
      "('Clothes', 'Milk')\n",
      "('Bread', 'Milk')\n",
      "('Shoes', 'Clothes', 'Bread')\n",
      "('Shoes', 'Clothes', 'Milk')\n",
      "('Shoes', 'Bread', 'Milk')\n",
      "('Clothes', 'Bread', 'Milk')\n",
      "('Shoes', 'Clothes', 'Bread', 'Milk')\n",
      "\n",
      "ðŸ”¹ Association Rules:\n",
      "('Shoes',) -> ('Bread',) (Confidence: 0.75)\n",
      "('Bread',) -> ('Shoes',) (Confidence: 0.60)\n",
      "('Shoes',) -> ('Milk',) (Confidence: 0.75)\n",
      "('Milk',) -> ('Shoes',) (Confidence: 0.60)\n",
      "('Clothes',) -> ('Bread',) (Confidence: 0.75)\n",
      "('Bread',) -> ('Clothes',) (Confidence: 0.60)\n",
      "('Clothes',) -> ('Milk',) (Confidence: 0.75)\n",
      "('Milk',) -> ('Clothes',) (Confidence: 0.60)\n",
      "('Bread',) -> ('Milk',) (Confidence: 0.60)\n",
      "('Milk',) -> ('Bread',) (Confidence: 0.60)\n",
      "('Shoes', 'Clothes') -> ('Bread',) (Confidence: 1.00)\n",
      "('Shoes', 'Clothes') -> ('Milk',) (Confidence: 1.00)\n",
      "('Shoes', 'Bread') -> ('Milk',) (Confidence: 0.67)\n",
      "('Shoes', 'Milk') -> ('Bread',) (Confidence: 0.67)\n",
      "('Bread', 'Milk') -> ('Shoes',) (Confidence: 0.67)\n",
      "('Clothes', 'Bread') -> ('Milk',) (Confidence: 0.67)\n",
      "('Clothes', 'Milk') -> ('Bread',) (Confidence: 0.67)\n",
      "('Bread', 'Milk') -> ('Clothes',) (Confidence: 0.67)\n",
      "('Shoes', 'Clothes') -> ('Bread', 'Milk') (Confidence: 1.00)\n",
      "('Shoes', 'Clothes', 'Bread') -> ('Milk',) (Confidence: 1.00)\n",
      "('Shoes', 'Clothes', 'Milk') -> ('Bread',) (Confidence: 1.00)\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Display Results\n",
    "print(\"\\nðŸ”¹ Frequent Itemsets:\")\n",
    "for itemset in frequent_itemsets:\n",
    "    print(itemset)\n",
    "\n",
    "print(\"\\nðŸ”¹ Association Rules:\")\n",
    "for rule in rules:\n",
    "    print(f\"{rule[0]} -> {rule[1]} (Confidence: {rule[2]:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Import necessary libraries\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = \"groceries_final.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataset into a list of transactions\n",
    "transactions = []\n",
    "for _, row in df.iterrows():\n",
    "    transaction = set(row.dropna().values)  # Remove NaNs and convert to a set\n",
    "    transactions.append(transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate Support of Each Item\n",
    "def calculate_support(transactions):\n",
    "    item_counts = {}\n",
    "    total_transactions = len(transactions)\n",
    "\n",
    "    for txn in transactions:\n",
    "        for item in txn:\n",
    "            item_counts[item] = item_counts.get(item, 0) + 1\n",
    "\n",
    "    support = {item: count / total_transactions for item, count in item_counts.items()}\n",
    "    return support\n",
    "\n",
    "# Calculate support for each item\n",
    "support = calculate_support(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define Minimum Item Support (MIS)\n",
    "MIS = {item: max(0.01, min(0.3, sup)) for item, sup in support.items()}  # MIS between 1% and 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m frequent_itemsets\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Generate frequent itemsets\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m frequent_itemsets \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_frequent_itemsets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMIS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupport\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 18\u001b[0m, in \u001b[0;36mgenerate_frequent_itemsets\u001b[1;34m(transactions, MIS, support, max_size)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m txn \u001b[38;5;129;01min\u001b[39;00m transaction_sets:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m itemset \u001b[38;5;129;01min\u001b[39;00m candidates:\n\u001b[1;32m---> 18\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitemset\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missubset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtxn\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     19\u001b[0m             itemset_counts[itemset] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m itemset, count \u001b[38;5;129;01min\u001b[39;00m itemset_counts\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Step 3: Frequent Itemset Generation using MIS\n",
    "def generate_frequent_itemsets(transactions, MIS, support, max_size=4):  # Increased max_size to 4\n",
    "    L = [item for item in support if support[item] >= MIS[item]]\n",
    "    L.sort(key=lambda item: MIS[item])  # Sorting by MIS values\n",
    "\n",
    "    frequent_itemsets = []\n",
    "    transaction_sets = [set(txn) for txn in transactions]  # Convert transactions to sets for fast lookup\n",
    "    \n",
    "    for k in range(1, max_size + 1):  # Limit itemset size\n",
    "        candidates = list(itertools.combinations(L, k))\n",
    "        valid_itemsets = []\n",
    "\n",
    "        # Using dictionary for efficient counting\n",
    "        itemset_counts = defaultdict(int)\n",
    "\n",
    "        for txn in transaction_sets:\n",
    "            for itemset in candidates:\n",
    "                if set(itemset).issubset(txn):\n",
    "                    itemset_counts[itemset] += 1\n",
    "\n",
    "        for itemset, count in itemset_counts.items():\n",
    "            itemset_support = count / len(transactions)\n",
    "            min_mis = min(MIS[item] for item in itemset)\n",
    "\n",
    "            if itemset_support >= min_mis:\n",
    "                valid_itemsets.append(itemset)\n",
    "\n",
    "        if valid_itemsets:\n",
    "            frequent_itemsets.extend(valid_itemsets)\n",
    "\n",
    "    return frequent_itemsets\n",
    "\n",
    "# Generate frequent itemsets\n",
    "frequent_itemsets = generate_frequent_itemsets(transactions, MIS, support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Frequent Itemsets (Debugging Step)\n",
    "df_frequent_itemsets = pd.DataFrame(frequent_itemsets, columns=[\"Itemset\"])\n",
    "print(\"\\nðŸ”¹ Frequent Itemsets (Showing First 10):\")\n",
    "print(df_frequent_itemsets.head(10))  # Show first 10 frequent itemsets\n",
    "print(\"\\nðŸ”¹ Frequent Itemset Sizes:\")\n",
    "print([len(itemset) for itemset in frequent_itemsets])  # Debug: Check frequent itemset sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Generate Association Rules\n",
    "def generate_rules(frequent_itemsets, transactions, min_conf=0.1):  # Lowered min_conf to 0.1\n",
    "    rules = []\n",
    "    transaction_sets = [set(txn) for txn in transactions]\n",
    "\n",
    "    for itemset in frequent_itemsets:\n",
    "        if isinstance(itemset, tuple) and len(itemset) > 1:\n",
    "            for i in range(1, len(itemset)):\n",
    "                for antecedent in itertools.combinations(itemset, i):\n",
    "                    consequent = tuple(set(itemset) - set(antecedent))\n",
    "\n",
    "                    support_antecedent = sum(1 for txn in transaction_sets if set(antecedent).issubset(txn)) / len(transactions)\n",
    "                    support_itemset = sum(1 for txn in transaction_sets if set(itemset).issubset(txn)) / len(transactions)\n",
    "\n",
    "                    confidence = support_itemset / support_antecedent if support_antecedent > 0 else 0\n",
    "\n",
    "                    if confidence >= min_conf:\n",
    "                        rules.append((antecedent, consequent, confidence))\n",
    "\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate association rules\n",
    "rules = generate_rules(frequent_itemsets, transactions, min_conf=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Association Rules (Debugging Step)\n",
    "df_rules = pd.DataFrame(rules, columns=[\"Antecedent\", \"Consequent\", \"Confidence\"])\n",
    "print(\"\\nðŸ”¹ Association Rules (Confidence 0.1, Showing First 10):\")\n",
    "print(df_rules.head(10))  # Show first 10 rules\n",
    "\n",
    "# Debugging: Print sample transactions\n",
    "print(\"\\nðŸ”¹ Sample Transactions (First 5):\")\n",
    "print(transactions[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
